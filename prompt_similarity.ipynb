{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import nlp_util\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data name: train\n",
      "Input start index: 0\n",
      "Input stop index: 10\n"
     ]
    }
   ],
   "source": [
    "#: User Input Prompts\n",
    "NAME = input('Input data name: ')\n",
    "START = int(input('Input start index: '))\n",
    "try:\n",
    "    STOP = int(input('Input stop index: '))\n",
    "except Exception:\n",
    "    STOP = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = utils.get_logger(f'{NAME}_prompt', __name__)\n",
    "\n",
    "#: Directory Paths\n",
    "data = pathlib.Path.cwd() / 'data'\n",
    "pkls = data / 'pkls'\n",
    "npys = data / 'npys'\n",
    "\n",
    "#: Load Prompts\n",
    "pkl = pkls / f'descr.pkl'\n",
    "prompts = pd.read_pickle(pkl)['prompt']\n",
    "\n",
    "#: Load Essay Set Ranges\n",
    "pkl = pkls / f'{NAME}.pkl'\n",
    "essay_set_counts = pd.read_pickle(pkl)['essay_set'].value_counts()\n",
    "essay_set_idxs = np.array([0] + [essay_set_counts[i] for i in range(1, 9)]).cumsum()\n",
    "essay_set_ranges = tuple(range(start, stop) for start, stop in zip(essay_set_idxs, essay_set_idxs[1:]))\n",
    "\n",
    "#: Load Corrections Array\n",
    "npy_corrs = npys / f'{NAME}_corrections.npy'\n",
    "corrs = np.load(npy_corrs)\n",
    "\n",
    "#: Load Prompt Similarity Arrays\n",
    "npy_count = npys / f'{NAME}_prompt_count.npy'\n",
    "if npy_count.exists():\n",
    "    arr_count = np.load(npy_count)\n",
    "else:\n",
    "    arr_count = np.empty(len(corrs))\n",
    "    arr_count.fill(np.nan)\n",
    "    \n",
    "npy_tfidf = npys / f'{NAME}_prompt_tfidf.npy'\n",
    "if npy_tfidf.exists():\n",
    "    arr_tfidf = np.load(npy_tfidf)\n",
    "else:\n",
    "    arr_tfidf = np.empty(len(corrs))\n",
    "    arr_tfidf.fill(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essay_set_counts = df['essay_set'].value_counts()\n",
    "# essay_set_idxs = np.array([0] + [essay_set_counts[i] for i in range(1, 9)]).cumsum()\n",
    "# essay_set_ranges = tuple(range(start, stop) for start, stop in zip(essay_set_idxs, essay_set_idxs[1:]))\n",
    "# essay_set_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"Return cleaned text with stopwords removed, no punctuation, and lemmatized.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Text string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned : str\n",
    "        Cleaned string.\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_proper = nlp_util.lower_with_proper(text)\n",
    "    lemmas = nlp_util.lemmatize(lower_proper)\n",
    "    cleaned = nlp_util.clean_stopwords_punctuation(lemmas)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prompts = [clean(prompt) for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prompt(index, ranges):\n",
    "    \"\"\"Return i of range in ranges that contains provided index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        Index of essay.\n",
    "    ranges : container of ranges\n",
    "        Container of ranges to search index inside.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    i : int\n",
    "        Index of range containing index of essay.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If provided index is not in any of the ranges.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, range_ in enumerate(ranges):\n",
    "        if index in range_:\n",
    "            return i\n",
    "    raise ValueError('index not in any range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_similarity(i_essay):\n",
    "    \"\"\"Return cosine similarities of the ith essay to its prompt.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    i_essay : (int, str)\n",
    "        Pair containing index and string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    i_count_tfidf : (i, float, float)\n",
    "        Triple tuple of ith essay cosine similarity measures using CountVectorizer and TfidfVectorizer. \n",
    "    \"\"\"\n",
    "    \n",
    "    i, essay = i_essay\n",
    "    clean_prompt = clean_prompts[find_prompt(i, essay_set_ranges)]\n",
    "    clean_essay = clean(essay)\n",
    "    \n",
    "    try:\n",
    "        count_meas = nlp_util.prompt_similarity(clean_prompt, clean_essay, vectorizer=CountVectorizer)\n",
    "        tfidt_meas = nlp_util.prompt_similarity(clean_prompt, clean_essay, vectorizer=TfidfVectorizer)\n",
    "    except BaseException as exc:\n",
    "        logger.exception(exc)\n",
    "        raise\n",
    "    else:\n",
    "        logger.info(f'Measured Cosine Similarity Index: {NAME} @ {i}')\n",
    "    return i, count_meas, tfidt_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_similarities_range(start=0, stop=None):\n",
    "    \"\"\"Save cosine similarities of all essays in the given range from start to stop.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start : int, optional\n",
    "        Slice start index.\n",
    "    \n",
    "    stop : int, optional\n",
    "        Slice stop index.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f'Start Index: {NAME} @ {start}')\n",
    "    \n",
    "    with multiprocessing.Pool() as pool:\n",
    "        i_count_tfidf = pool.map(assign_similarity, enumerate(corrs[START:STOP], start=start))\n",
    "    \n",
    "    idxs, counts, tfidfs = map(list, zip(*i_count_tfidf))\n",
    "    \n",
    "    arr_count[idxs] = counts\n",
    "    np.save(npy_count, arr_count)\n",
    "\n",
    "    arr_tfidf[idxs] = tfidfs\n",
    "    np.save(npy_tfidf, arr_tfidf)\n",
    "    \n",
    "    logger.info(f'Stop Index: {NAME} @ {stop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_similarities_range(START, STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
