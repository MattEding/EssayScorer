{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob, Word, WordList\n",
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from utils import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pathlib.Path.cwd() / 'data'\n",
    "pkls = data / 'pkls'\n",
    "npys = data / 'npys'\n",
    "\n",
    "descr = pd.read_pickle(pkls / 'descr.pkl')\n",
    "train = pd.read_pickle(pkls / 'train.pkl')\n",
    "tr_corr = np.load(npys / 'train_corrections.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = descr['prompt']\n",
    "essays = train['essay']\n",
    "corpus = pd.concat([pd.Series(prompts[0]), essays[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.6434103964757235),\n",
       " (4, 0.4135763891545543),\n",
       " (5, 0.40486881513293227),\n",
       " (1, 0.2886150127292031),\n",
       " (2, 0.2875083056936687)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(stop_words='english')\n",
    "X_count = count_vec.fit_transform(corpus)\n",
    "doc_term_mtx_count = pd.DataFrame(X_count.toarray(), columns=count_vec.get_feature_names())\n",
    "\n",
    "similarity_essays_to_prompt(doc_term_mtx_count, cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.4589585009379219),\n",
       " (5, 0.22227805596964267),\n",
       " (4, 0.20122636625176427),\n",
       " (1, 0.19135359762819126),\n",
       " (2, 0.14588618973159329)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf_vec.fit_transform(corpus)\n",
    "doc_term_mtx_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vec.get_feature_names())\n",
    "\n",
    "similarity_essays_to_prompt(doc_term_mtx_tfidf, cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob Spellcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Size Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_words = tb_correct.tokenize()\n",
    "orig_words = tb_essay.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003156565656565657"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(not word in tb_correct for word in tb_essay) / len(tb_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049586776859504134"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(not word in corr_words for word in orig_words) / len(orig_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([not word in corr_words for word in orig_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.69 s ± 54.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([not word in (tb_correct.tokenize()) for word in tb_essay.tokenize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 s ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([not word in frozenset(tb_correct.tokenize()) for word in tb_essay.tokenize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 s ± 28.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum([not word in set(tb_correct.tokenize()) for word in tb_essay.tokenize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.54 ms ± 91.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tb_correct.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tb_correct.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 ms ± 41.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tokens.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.WordList"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_correct.tokenize().lemmatize().__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Dear', '@', 'ORGANIZATION1', ',', 'The', 'computer', 'blinked', 'to', 'life', 'and', 'an', 'image', 'of', 'a', 'blonde', 'haired', 'girl', 'filled', 'the', 'screen', '.', 'It', 'wa', 'easy', 'to', 'find', 'out', 'how', 'life', 'wa', 'in', '@', 'LOCATION2', ',', 'thanks', 'to', 'the', 'actual', '@', 'CAPS1', 'girl', 'explaining', 'it', '.', 'Going', 'to', 'the', 'library', 'would', \"n't\", 'have', 'filled', 'one', 'with', 'this', 'priceless', 'information', 'and', 'human', 'interaction', '.', 'Computers', 'are', 'a', 'necessity', 'of', 'life', 'if', 'society', 'wish', 'to', 'grow', 'and', 'expand', '.', 'They', 'should', 'be', 'supported', 'because', 'they', 'teach', 'hand', 'eye', 'coordination', ',', 'give', 'people', 'the', 'ability', 'to', 'learn', 'about', 'faraway', 'place', ',', 'and', 'allow', 'people', 'to', 'talk', 'to', 'others', 'online', '.', 'Firstly', ',', 'computer', 'help', 'teach', 'hand', 'eye', 'coordination', '.', 'And-eye', 'coordination', 'is', 'a', 'useful', 'ability', 'that', 'is', 'used', 'to', 'expel', 'in', 'sport', '.', 'In', 'a', 'recent', 'survey', ',', '@', 'PERCENT1', 'of', 'kiss', 'felt', 'their', 'hand', 'eye', 'coordination', 'improves', 'after', 'computer', 'use', '.', 'Even', 'a', 'simple', 'thing', 'like', 'tying', 'can', 'build', 'up', 'this', 'skill', '.', 'Famous', 'neurologist', '@', 'CAPS2', '@', 'PERSON1', 'stated', 'in', 'an', 'article', 'last', 'week', 'that', ',', '``', '@', 'CAPS3', 'and', 'computer', 'strength', 'the', '@', 'CAPS2', '.', 'When', 'on', 'the', 'computer', ',', 'you', 'automatically', 'process', 'what', 'the', 'eye', 'see', 'into', 'a', 'command', 'for', 'your', 'hand', '.', \"''\", '@', 'CAPS4', 'hand', 'eye', 'coordination', 'can', 'improve', 'people', 'in', 'sport', 'such', 'a', 'baseball', 'and', 'basketball', '.', 'Of', 'someone', 'wa', \"n't\", 'to', 'become', 'better', 'in', 'these', 'sport', ',', 'all', 'they', \"'d\", 'need', 'to', 'do', 'wa', 'turn', 'on', 'the', 'computer', '.', 'Once', 'people', 'become', 'better', 'at', 'sport', ',', 'they', \"'re\", 'more', 'likely', 'to', 'play', 'them', 'and', 'become', 'more', 'healthy', '.', 'In', 'reality', ',', 'computer', 'can', 'help', 'with', 'exercising', 'instead', 'of', 'increasing', 'it', '.', 'Additional', ',', 'computer', 'allow', 'people', 'to', 'access', 'information', 'about', 'faraway', 'place', 'and', 'people', '.', 'Of', 'someone', 'wanted', 'to', 'research', '@', 'LOCATION1', ',', 'all', 'they', \"'d\", 'need', 'to', 'do', 'wa', 'type', 'in', 'a', 'search', 'would', 'be', 'presented', 'to', 'them', 'in', 'it', 'would', 'link', 'forever', 'to', 'search', 'through', 'countless', 'thing', '.', 'Also', ',', 'having', 'the', 'ability', 'to', 'learn', 'about', 'culture', 'can', 'make', 'people', 'people', 'and', 'their', 'culture', ',', 'they', 'understand', 'others', 'something', '.', 'Increase', 'tolerable', 'people', 'are', '.', 'Computers', 'are', 'a', 'resourceful', 'tool', 'that', 'they', 'can', 'help', 'people', 'in', 'every', 'different', 'aspect', 'of', 'life', '.', 'Lastly', ',', 'computer', 'and', 'in', 'technology', 'can', 'allow', 'people', 'to', 'chat', '.', 'Computer', 'chat', 'and', 'video', 'chat', 'can', 'help', 'the', 'all', 'different', 'nation', '.', 'Bring', 'on', 'good', 'term', 'place', 'other', 'than', 'can', 'help', 'u', 'understand', 'story', 'come', 'out', 'about', 'something', 'that', 'happened', 'in', '@', 'LOCATION3', ',', 'people', 'can', 'just', 'go', 'on', 'their', 'computer', 'and', 'ask', 'an', 'actual', '@', 'LOCATION3', 'citizen', 'their', 'take', 'on', 'the', 'matter', '.', 'Also', ',', 'video', 'chat', 'and', 'online', 'conversation', 'can', 'cut', 'down', 'on', 'expensive', 'phone', 'bill', '.', 'To', 'one', 'want', 'to', 'pay', 'more', 'than', 'they', 'have', 'to', 'in', 'this', 'economy', '.', 'Another', 'good', 'point', 'is', 'that', 'you', 'can', 'access', 'family', 'member', 'you', 'scarcely', 'visit', '.', 'It', 'can', 'help', 'you', 'connect', 'within', 'your', 'own', 'family', 'more', '.', 'Obviously', ',', 'computer', 'are', 'a', 'useful', 'aid', 'in', 'today', 'era', '.', 'their', 'advancement', 'push', 'the', 'world', 'forward', 'to', 'a', 'better', 'place', '.', 'Computers', 'can', 'help', 'people', 'because', 'they', 'help', 'teach', 'handed', 'coordination', ',', 'give', 'people', 'the', 'ability', 'to', 'learn', 'about', 'faraway', 'place', 'and', 'people', ',', 'and', 'allow', 'people', 'to', 'talk', 'online', 'with', 'others', '.', 'Think', 'of', 'a', 'world', 'with', 'no', 'computer', 'or', 'technological', 'advancement', '.', 'The', 'world', 'would', 'be', 'secured', 'and', 'unified', ',', 'contact', 'between', 'people', 'scare', ',', 'and', 'information', 'even', '.', 'The', 'internet', 'is', 'like', 'thousand', 'or', 'library', 'put', 'together', '.', 'Nobody', 'would', 'know', 'much', 'about', 'other', 'nation', 'and', 'news', 'would', 'travel', 'slower', '.', 'Is', 'that', 'the', 'kind', 'of', 'place', 'you', 'want', 'people', 'to', 'live', 'in', '?'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539807998465871"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spelling_confidence(wordlist, agg_func=np.max):\n",
    "    return sum(agg_func([conf for _, conf in word.spellcheck()]) for word in wordlist) / len(wordlist)\n",
    "\n",
    "spelling_confidence(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = train[train['essay_set'] == 1]\n",
    "low = set1[set1['domain1_score'] < 4]\n",
    "high = set1[set1['domain1_score'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id                                                         545\n",
       "essay_set                                                          1\n",
       "essay              I think that computers are amazing. Computers ...\n",
       "domain1_score                                                      2\n",
       "domain2_score                                                    NaN\n",
       "domain1_percent                                                    0\n",
       "domain2_percent                                                  NaN\n",
       "Name: 542, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
